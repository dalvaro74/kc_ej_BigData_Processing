# Pr√°ctica Big Data Processing. 

Este proyecto escrito en Scala corresponde a la pr√°ctica que tuve que presentar como para el m√≥dulo Big Data Processing del BootCamp de Big Data & Machine Learning que curs√© en KeepCoding en 2019/2020.

## Comenzando üöÄ

El enunciado del ejercicio puede encontrarse [aqu√≠](Enunciado.md)

### Pre-requisitos üìã
- Java 8
- [IntelliJ](https://www.jetbrains.com/idea/) IDE para programar en Scala
- [Scala 2.11.12](https://www.scala-lang.org/)
- [Apache Kafka 2.12-2.3.0](https://kafka.apache.org/)
- [sbt](https://www.scala-sbt.org/)

### Instalaci√≥n üîß

El proyecto se ha desarrollado y probado usando el sistema operativo Mac OS Catalina 10.15

Las librer√≠as usadas dentro del proyecto son las siguientes:

- Spark Core
- Spark Sql
- Spark Streaming
- Spark Streaming Kafka
- Spark Sql Kafka

### Configuraci√≥n ‚öôÔ∏è
Se ha usado **sbt** como gestor de dependencias. Dentro del archivo build.sbt se encuentran las librer√≠as necesarias para el correcto funcionamiento del proyecto.

Dentro de la carpeta **Resources** se encuentra el fichero lista_negra.dat que contiene las palabras consideradas como "negativas".

Tambi√©n dentro de la carpeta **Resources** se encuentran los csv con la informaci√≥n de dispositivos, mensajes y usuarios. Los Ficheros son los siguientes: 

- **mensajes.csv** con los mensajes capturados por los diferentes dispositivos IoT.
- **dispositivos.csv** con la informaci√≥n de los diferentes dispositivos
- **usuarios.csv** con todos los usuarios de Celebram
- **palabras_excluir.dat** este fichero contiene palabaras que no se tienen en cuenta para el estudio (conjunciones, art√≠culos y preposiciones)

## Deployment üì¶

Al ejecutarse la aplicaci√≥n (fichero Main.scala), se cargar√° autom√°ticamente los csv de Usuarios y dispositivos IoT que estar√°n guardados en los csv correspondientes en la carpeta **Resources**.

Despu√©s se iniciar√° la espera de mensajes desde Kafka, en este paso tendremos que ir a la consola de Kafka y ejecutar el siguiente comando para cargar el csv con los mensajes:

```bash
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test < ../../Proyectos_software/KC_Practica_BigData_Processing/src/main/resources/mensajes.csv
```

El sistema leer√° el fichero de palabras exclu√≠das (art√≠culos, preposiciones,.. ect) y no tendr√° en cuenta dichas palabras para el an√°lisis de los resultados.

Cuando acabe la ventana (para las pruebas se ha establecido en 10 segundos) se mostrar√° el resultado con las 10 palabras m√°s usadas, tambi√©n se comprobar√° si la palabra m√°s repetida coincide con alguna de las plabras de la lista negra, en ese caso, se mostrar√° un aviso por consola.

## Obtenci√≥n de mensajes üñ•Ô∏è

Para la obtenci√≥n de los mensajes, he creado un proyecto a parte en Scala que descarga Tweets en streaming y los almacena en un fichero de texto. Las librer√≠as usadas han sido:

- Spark Streaming
- Spark Streaming Twitter
- twitter4j

Este es el c√≥digo usado para tal fin:

```scala
import org.apache.spark.streaming.dstream.DStream
import org.apache.spark.streaming.twitter.TwitterUtils
import org.apache.spark.streaming.{Seconds, StreamingContext}
import org.apache.spark.{SparkConf, SparkContext}
import twitter4j.Status

object pruebasFran extends App {
    // En este fichero estan las funciones que se usan para clasificar tweets etc
    import Utils._

    // Configurar spark, nombre e indicamos que usamos todos los cores disponibles
    val sparkConfiguration = new SparkConf()
            .setAppName("Clasificar Tweets")
            .setMaster("local[*]")

    // Crearmos el contexto con la configuracion anterior
    val sparkContext = new SparkContext(sparkConfiguration)

    // Configuramos el streaming cada 5 segundos
    val streamingContext = new StreamingContext(sparkContext, Seconds(5))

    // Crear el stream de Twitter (mirar README para saber c√≥mo configurar las credenciales)
    var tweets: DStream[Status] = TwitterUtils.createStream(streamingContext, None)

    tweets = tweets.filter(_.getLang == "es")  // Filtramos tweets en espanol
    tweets = tweets.filter(tweetText => !(tweetText.getText contains "@"))  // Quitamos las menciones

    // Guardar en ficheros de texto
    tweets.map(tweetText => tweetText.getText).saveAsTextFiles("prueba.txt")

    // Mostrar por consola
    //tweets.map(tweetText => tweetText.getText).print()
    
    // Lanzamos el setreaming
    streamingContext.start()

    // Esperamos hasta que alguien lo pare
    streamingContext.awaitTermination()
}
```

## Aclaraciones ‚úèÔ∏è

Al esquema de los mensajes he decidido incluir un nuevo campo correspondiente al ID del dispositivo IoT.

Al esquema de usuarios le he cambiado el tipo de dato a Int porque me parece m√°s √≥ptimo a nivel de BBDD.

A la hora de tratar los mensajes, se usa una funci√≥n para desencriptarlos y no se tienen en cuenta las preposiciones, conjunciones ni art√≠culos.

No he sido capaz de recuperar el timestamp, tampoco de obtener el top 10 porque al ser streaming da error. Al hacer la comprobaci√≥n contra la lista negra, tambi√©n me da error al hacer un "count" para comprobar si existe alguna palabra en dicha lista negra.

## Expresiones de Gratitud üéÅ

* Comenta a otros sobre este proyecto üì¢
* Da las gracias p√∫blicamente ü§ì
* S√≠gueme en <a href="https://twitter.com/AsensiFj">Twitter</a> üê¶